{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "tags": [],
    "ExecuteTime": {
     "end_time": "2025-04-11T07:08:41.883530Z",
     "start_time": "2025-04-11T07:08:40.564746Z"
    }
   },
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch\n",
    "import numpy as np\n",
    "import os\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import random\n",
    "\n",
    "os.environ['KMP_DUPLICATE_LIB_OK'] = 'True'\n",
    "device = \"cuda\""
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.autograd.anomaly_mode.set_detect_anomaly at 0x1292e613af0>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "id": "2fded8d5d8c4a8d9",
   "metadata": {
    "collapsed": false,
    "tags": [],
    "ExecuteTime": {
     "end_time": "2025-04-11T07:08:41.899476Z",
     "start_time": "2025-04-11T07:08:41.884527Z"
    }
   },
   "source": [
    "class Physionet(Dataset):\n",
    "    def __init__(self, root, train=\"train\"):\n",
    "        self.audios = torch.tensor(np.load(os.path.join(root, train + \"_audios.npy\"))).cuda()\n",
    "        self.labels = torch.tensor(np.load(os.path.join(root, train + \"_labels.npy\")))\n",
    "        self.labels = self.labels[:, ].cuda()\n",
    "        # self.labels = torch.argmax(self.labels, dim=1)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.audios[index], self.labels[index]"
   ],
   "outputs": [],
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "id": "16b2a8bdcb173e40",
   "metadata": {
    "collapsed": false,
    "tags": [],
    "ExecuteTime": {
     "end_time": "2025-04-11T07:09:00.811116Z",
     "start_time": "2025-04-11T07:08:51.265078Z"
    }
   },
   "source": [
    "data_path = \"..\\\\tydata\\\\audio\"\n",
    "\n",
    "train_dataset = Physionet(data_path, train=\"train\")\n",
    "val_dataset = Physionet(data_path, train=\"val\")\n",
    "test_dataset = Physionet(data_path, train=\"test\")\n",
    "\n",
    "print(f\"Train: {len(train_dataset)}\")\n",
    "print(f\"Val: {len(val_dataset)}\")\n",
    "print(f\"Test: {len(test_dataset)}\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 70235\n",
      "Val: 8779\n",
      "Test: 8780\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "id": "44498d343a192a4",
   "metadata": {
    "collapsed": false,
    "tags": [],
    "ExecuteTime": {
     "end_time": "2025-04-11T07:09:01.136315Z",
     "start_time": "2025-04-11T07:09:01.120524Z"
    }
   },
   "source": [
    "batch_size = 64\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"
   ],
   "outputs": [],
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "id": "d71cf1ba243e0e2f",
   "metadata": {
    "collapsed": false,
    "tags": [],
    "ExecuteTime": {
     "end_time": "2025-04-11T07:09:02.200646Z",
     "start_time": "2025-04-11T07:09:02.154800Z"
    }
   },
   "source": [
    "import math\n",
    "\n",
    "# 首先，在函数get_freq_indices(method)中，根据给定的method参数，确定了需要选择的频率索引。method参数可以是以下几种取值：\n",
    "# 'top1','top2','top4','top8','top16','top32','bot1','bot2','bot4','bot8','bot16','bot32','low1','low2','low4','low8','low16','low32'。\n",
    "# 根据不同的取值，函数会返回相应数量的频率索引列表（mapper_x和mapper_y）。\n",
    "def get_freq_indices_l(method):\n",
    "    assert method in ['top1', 'top2', 'top4', 'top8', 'top16', 'top32',\n",
    "                      'bot1', 'bot2', 'bot4', 'bot8', 'bot16', 'bot32',\n",
    "                      'low1', 'low2', 'low4', 'low8', 'low16', 'low32']\n",
    "    num_freq = int(method[3:])  # 当method为16时，num_freq=16\n",
    "    if 'top' in method:\n",
    "        all_top_indices_x = [0, 0, 2, 6, 0, 0, 0, 0, 4, 6, 6, 6, 1, 5, 6, 5, 3, 3, 5, 6, 2, 0, 5, 1, 4, 3, 6, 4, 5, 4,\n",
    "                             4, 3]\n",
    "        all_top_indices_y = [1, 6, 3, 0, 4, 2, 0, 5, 0, 6, 1, 2, 2, 0, 3, 1, 3, 0, 2, 4, 0, 3, 5, 5, 4, 6, 5, 2, 6, 1,\n",
    "                             5, 4]\n",
    "        mapper_x = all_top_indices_x[:num_freq]\n",
    "        mapper_y = all_top_indices_y[:num_freq]\n",
    "    elif 'low' in method:\n",
    "        all_low_indices_x = [0, 0, 1, 1, 0, 2, 2, 1, 2, 0, 3, 4, 0, 1, 3, 0, 1, 2, 3, 4, 5, 0, 1, 2, 3, 4, 5, 6, 1, 2,\n",
    "                             3, 4]\n",
    "        all_low_indices_y = [0, 1, 0, 1, 2, 0, 1, 2, 2, 3, 0, 0, 4, 3, 1, 5, 4, 3, 2, 1, 0, 6, 5, 4, 3, 2, 1, 0, 6, 5,\n",
    "                             4, 3]\n",
    "        mapper_x = all_low_indices_x[:num_freq]\n",
    "        mapper_y = all_low_indices_y[:num_freq]\n",
    "    elif 'bot' in method:\n",
    "        all_bot_indices_x = [6, 1, 3, 3, 2, 4, 1, 2, 4, 4, 5, 1, 4, 6, 2, 5, 6, 1, 6, 2, 2, 4, 3, 3, 5, 5, 6, 2, 5, 5,\n",
    "                             3, 6]\n",
    "        all_bot_indices_y = [6, 4, 4, 6, 6, 3, 1, 4, 4, 5, 6, 5, 2, 2, 5, 1, 4, 3, 5, 0, 3, 1, 1, 2, 4, 2, 1, 1, 5, 3,\n",
    "                             3, 3]\n",
    "        mapper_x = all_bot_indices_x[:num_freq]\n",
    "        mapper_y = all_bot_indices_y[:num_freq]\n",
    "    else:\n",
    "        raise NotImplementedError\n",
    "\n",
    "    return mapper_x, mapper_y\n",
    "\n",
    "\n",
    "def get_freq_indices_r(method):\n",
    "    assert method in ['top1', 'top2', 'top4', 'top8', 'top16', 'top32',\n",
    "                      'bot1', 'bot2', 'bot4', 'bot8', 'bot16', 'bot32',\n",
    "                      'low1', 'low2', 'low4', 'low8', 'low16', 'low32']\n",
    "    num_freq = int(method[3:])  # 当method为16时，num_freq=16\n",
    "    if 'top' in method:\n",
    "        all_top_indices_x = [0, 2, 6, 0, 0, 0, 3, 2, 5, 2, 1, 1, 0, 0, 3, 1, 3, 4, 5, 6, 2, 3, 6, 5, 6, 1, 6, 4, 4, 4,\n",
    "                             4, 1]\n",
    "        all_top_indices_y = [3, 0, 6, 4, 1, 0, 1, 1, 1, 6, 5, 0, 6, 2, 3, 3, 0, 2, 0, 0, 2, 2, 3, 2, 1, 4, 4, 0, 4, 5,\n",
    "                             6, 6]\n",
    "        mapper_x = all_top_indices_x[:num_freq]\n",
    "        mapper_y = all_top_indices_y[:num_freq]\n",
    "    elif 'low' in method:\n",
    "        all_low_indices_x = [0, 0, 1, 1, 0, 2, 2, 1, 2, 0, 3, 4, 0, 1, 3, 0, 1, 2, 3, 4, 5, 0, 1, 2, 3, 4, 5, 6, 1, 2,\n",
    "                             3, 4]\n",
    "        all_low_indices_y = [0, 1, 0, 1, 2, 0, 1, 2, 2, 3, 0, 0, 4, 3, 1, 5, 4, 3, 2, 1, 0, 6, 5, 4, 3, 2, 1, 0, 6, 5,\n",
    "                             4, 3]\n",
    "        mapper_x = all_low_indices_x[:num_freq]\n",
    "        mapper_y = all_low_indices_y[:num_freq]\n",
    "    elif 'bot' in method:\n",
    "        all_bot_indices_x = [6, 1, 3, 3, 2, 4, 1, 2, 4, 4, 5, 1, 4, 6, 2, 5, 6, 1, 6, 2, 2, 4, 3, 3, 5, 5, 6, 2, 5, 5,\n",
    "                             3, 6]\n",
    "        all_bot_indices_y = [6, 4, 4, 6, 6, 3, 1, 4, 4, 5, 6, 5, 2, 2, 5, 1, 4, 3, 5, 0, 3, 1, 1, 2, 4, 2, 1, 1, 5, 3,\n",
    "                             3, 3]\n",
    "        mapper_x = all_bot_indices_x[:num_freq]\n",
    "        mapper_y = all_bot_indices_y[:num_freq]\n",
    "    else:\n",
    "        raise NotImplementedError\n",
    "\n",
    "    return mapper_x, mapper_y\n",
    "\n",
    "\n",
    "# 多个频率+通道+空间注意力机制\n",
    "class MultiSpectralChannelSpatialAttentionLayer(torch.nn.Module):\n",
    "    def __init__(self, channel, dct_h, dct_w, reduction=16, freq_sel_method='top8', side='l'):\n",
    "        super(MultiSpectralChannelSpatialAttentionLayer, self).__init__()\n",
    "        self.reduction = reduction\n",
    "        self.dct_h = dct_h\n",
    "        self.dct_w = dct_w\n",
    "\n",
    "        if side == 'l':\n",
    "            mapper_x, mapper_y = get_freq_indices_l(freq_sel_method)\n",
    "        else:\n",
    "            mapper_x, mapper_y = get_freq_indices_r(freq_sel_method)\n",
    "        self.num_split = len(mapper_x)\n",
    "        mapper_x = [temp_x * (dct_h // 7) for temp_x in mapper_x]\n",
    "        mapper_y = [temp_y * (dct_w // 7) for temp_y in mapper_y]\n",
    "        # make the frequencies in different sizes are identical to a 7x7 frequency space\n",
    "        # eg, (2,2) in 14x14 is identical to (1,1) in 7x7\n",
    "\n",
    "        # frequency\n",
    "        self.dct_layer = MultiSpectralDCTLayer(dct_h, dct_w, mapper_x, mapper_y, channel)\n",
    "        # channel\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(channel, channel // reduction, bias=False),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(channel // reduction, channel, bias=False),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        # spatial\n",
    "        self.SpatialAttention = SpatialAttention()\n",
    "\n",
    "    def forward(self, x):\n",
    "        n, c, h, w = x.shape\n",
    "        x_pooled = x\n",
    "        if h != self.dct_h or w != self.dct_w:\n",
    "            x_pooled = torch.nn.functional.adaptive_avg_pool2d(x, (self.dct_h, self.dct_w))\n",
    "            # If you have concerns about one-line-change, don't worry.   :)\n",
    "            # In the ImageNet models, this line will never be triggered. \n",
    "            # This is for compatibility in instance segmentation and object detection.\n",
    "        y = self.dct_layer(x_pooled)\n",
    "\n",
    "        y = self.fc(y).view(n, c, 1, 1)\n",
    "        y = x * y.expand_as(x)\n",
    "\n",
    "        y = self.SpatialAttention(y)\n",
    "\n",
    "        return y\n",
    "\n",
    "\n",
    "class MultiSpectralDCTLayer(nn.Module):\n",
    "    \"\"\"\n",
    "    Generate dct filters\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, height, width, mapper_x, mapper_y, channel):\n",
    "        super(MultiSpectralDCTLayer, self).__init__()\n",
    "\n",
    "        assert len(mapper_x) == len(mapper_y)\n",
    "        # print(f\"x {channel}  weight {len(mapper_x)}\")\n",
    "        # assert channel % len(mapper_x) == 0\n",
    "\n",
    "        self.num_freq = len(mapper_x)\n",
    "\n",
    "        # fixed DCT init\n",
    "        self.register_buffer('weight', self.get_dct_filter(height, width, mapper_x, mapper_y, channel))\n",
    "\n",
    "        # fixed random init\n",
    "        # self.register_buffer('weight', torch.rand(channel, height, width))\n",
    "\n",
    "        # learnable DCT init\n",
    "        # self.register_parameter('weight', self.get_dct_filter(height, width, mapper_x, mapper_y, channel))\n",
    "\n",
    "        # learnable random init\n",
    "        # self.register_parameter('weight', torch.rand(channel, height, width))\n",
    "\n",
    "        # num_freq, h, w\n",
    "\n",
    "    def forward(self, x):\n",
    "        assert len(x.shape) == 4, 'x must been 4 dimensions, but got ' + str(len(x.shape))\n",
    "        # n, c, h, w = x.shape\n",
    "        # print(f\"x :{x.shape}  weight: {self.weight.shape}\")\n",
    "        x = x * self.weight\n",
    "\n",
    "        result = torch.sum(x, dim=[2, 3])\n",
    "        return result\n",
    "\n",
    "    def build_filter(self, pos, freq, POS):\n",
    "        result = math.cos(math.pi * freq * (pos + 0.5) / POS) / math.sqrt(POS)\n",
    "        if freq == 0:\n",
    "            return result\n",
    "        else:\n",
    "            return result * math.sqrt(2)\n",
    "\n",
    "    def get_dct_filter(self, tile_size_x, tile_size_y, mapper_x, mapper_y, channel):\n",
    "        dct_filter = torch.zeros(channel, tile_size_x, tile_size_y)\n",
    "\n",
    "        c_part = channel // len(mapper_x)\n",
    "\n",
    "        for i, (u_x, v_y) in enumerate(zip(mapper_x, mapper_y)):\n",
    "            for t_x in range(tile_size_x):\n",
    "                for t_y in range(tile_size_y):\n",
    "                    dct_filter[i * c_part: (i + 1) * c_part, t_x, t_y] = self.build_filter(t_x, u_x,\n",
    "                                                                                           tile_size_x) * self.build_filter(\n",
    "                        t_y, v_y, tile_size_y)\n",
    "\n",
    "        return dct_filter\n",
    "\n",
    "\n",
    "# 通道注意力\n",
    "class ChannelAttention(nn.Module):\n",
    "    def __init__(self, in_channels, reduction_ratio=16):\n",
    "        super(ChannelAttention, self).__init__()\n",
    "        self.avg_pool = nn.AdaptiveAvgPool2d(1)\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(in_channels, in_channels // reduction_ratio),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(in_channels // reduction_ratio, in_channels)\n",
    "        )\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        b, c, _, _ = x.size()\n",
    "        y = self.avg_pool(x).view(b, c)\n",
    "        y = self.fc(y).view(b, c, 1, 1)\n",
    "        return x * self.sigmoid(y)\n",
    "\n",
    "\n",
    "# 空间注意力\n",
    "class SpatialAttention(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SpatialAttention, self).__init__()\n",
    "        self.conv = nn.Conv2d(2, 1, kernel_size=7, padding=3)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        max_pool = torch.max(x, dim=1, keepdim=True)[0]\n",
    "        avg_pool = torch.mean(x, dim=1, keepdim=True)\n",
    "        y = torch.cat([max_pool, avg_pool], dim=1)\n",
    "        y = self.conv(y)\n",
    "        return x * self.sigmoid(y)\n",
    "\n",
    "\n",
    "# 通道+空间注意力 CBAM\n",
    "class CBAM(nn.Module):\n",
    "    def __init__(self, in_channels, reduction_ratio=16):\n",
    "        super(CBAM, self).__init__()\n",
    "        self.channel_attention = ChannelAttention(in_channels, reduction_ratio)\n",
    "        self.spatial_attention = SpatialAttention()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.channel_attention(x)\n",
    "        x = self.spatial_attention(x)\n",
    "        return x"
   ],
   "outputs": [],
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "id": "5946d0b6abaa385",
   "metadata": {
    "collapsed": false,
    "tags": [],
    "ExecuteTime": {
     "end_time": "2025-04-11T07:09:10.552029Z",
     "start_time": "2025-04-11T07:09:02.832139Z"
    }
   },
   "source": [
    "import librosa\n",
    "\n",
    "class BasicBlock(nn.Module):\n",
    "    expansion = 1\n",
    "\n",
    "    def __init__(self, in_planes, planes, stride=1):\n",
    "        super(BasicBlock, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(\n",
    "            in_planes, planes, kernel_size=3, stride=stride, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(planes)\n",
    "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3,\n",
    "                               stride=1, padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(planes)\n",
    "\n",
    "        self.shortcut = nn.Sequential()\n",
    "        if stride != 1 or in_planes != self.expansion * planes:\n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Conv2d(in_planes, self.expansion * planes,\n",
    "                          kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(self.expansion * planes)\n",
    "            )\n",
    "        self.relu1 = nn.ReLU(inplace=True)\n",
    "        self.relu2 = nn.ReLU(inplace=True)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.relu1(self.bn1(self.conv1(x)))\n",
    "        out = self.bn2(self.conv2(out))\n",
    "        out += self.shortcut(x)\n",
    "        out = self.relu2(out)\n",
    "        return out\n",
    "\n",
    "\n",
    "class Bottleneck(nn.Module):\n",
    "    expansion = 4\n",
    "\n",
    "    def __init__(self, in_planes, planes, stride=1):\n",
    "        super(Bottleneck, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_planes, planes, kernel_size=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(planes)\n",
    "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3,\n",
    "                               stride=stride, padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(planes)\n",
    "        self.conv3 = nn.Conv2d(planes, self.expansion *\n",
    "                               planes, kernel_size=1, bias=False)\n",
    "        self.bn3 = nn.BatchNorm2d(self.expansion * planes)\n",
    "\n",
    "        self.shortcut = nn.Sequential()\n",
    "        if stride != 1 or in_planes != self.expansion * planes:\n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Conv2d(in_planes, self.expansion * planes,\n",
    "                          kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(self.expansion * planes)\n",
    "            )\n",
    "        self.relu1 = nn.ReLU(inplace=True)\n",
    "        self.relu2 = nn.ReLU(inplace=True)\n",
    "        self.relu3 = nn.ReLU(inplace=True)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.relu1(self.bn1(self.conv1(x)))\n",
    "        out = self.relu2(self.bn2(self.conv2(out)))\n",
    "        out = self.bn3(self.conv3(out))\n",
    "        out += self.shortcut(x)\n",
    "        out = self.relu3(out)\n",
    "        return out\n",
    "\n",
    "\n",
    "class ZHJNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        global _mapper_x, _mapper_y  #ty\n",
    "        c2wh_l = [(36, 96), (18, 48), (18, 48), (9, 24), (9, 24), (9, 24)]  #ty big left\n",
    "        c2wh_r = [(36, 96), (36, 96), (18, 48), (18, 48), (18, 48), (9, 24)]  #ty small right\n",
    "        c_l = [16, 64, 128, 256, 512, 512]\n",
    "        c_r = [16, 16, 32, 64, 128, 512]\n",
    "\n",
    "        self.in_channels = 16\n",
    "\n",
    "        self.filterbank_l = torch.tensor(librosa.filters.mel(\n",
    "            sr=1000,\n",
    "            n_fft=1024,\n",
    "            n_mels=40,\n",
    "            fmin=0.0,\n",
    "            fmax=None,\n",
    "            htk=False,\n",
    "            norm='slaney',\n",
    "        ).T).cuda()\n",
    "        self.mask_l = (self.filterbank_l == 0).float().unsqueeze(0).cuda()\n",
    "        self.inv_mask_l = 1 - self.mask_l\n",
    "        self.filterbank_non_trainable_l = self.filterbank_l.clone().detach()\n",
    "        self.filterbank_non_trainable_l.requires_grad = False\n",
    "        self.filterbank_l = nn.Parameter(self.filterbank_l)\n",
    "        print(\"left\",self.filterbank_l.device, self.mask_l.device)\n",
    "        \n",
    "        self.filterbank_r = torch.tensor(librosa.filters.mel(\n",
    "            sr=1000,\n",
    "            n_fft=1024,\n",
    "            n_mels=40,\n",
    "            fmin=0.0,\n",
    "            fmax=None,\n",
    "            htk=False,\n",
    "            norm='slaney',\n",
    "        ).T).cuda()\n",
    "        self.mask_r = (self.filterbank_r == 0).float().unsqueeze(0).cuda()\n",
    "        self.inv_mask_r = 1 - self.mask_r\n",
    "        self.filterbank_non_trainable_r = self.filterbank_r.clone().detach()\n",
    "        self.filterbank_non_trainable_r.requires_grad = False\n",
    "        self.filterbank_r = nn.Parameter(self.filterbank_r)\n",
    "        print(\"right\",self.filterbank_r.device, self.mask_r.device)\n",
    "        \n",
    "        self.conv_l_0 = nn.Sequential(\n",
    "            nn.Conv2d(1, 16, kernel_size=7, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(16),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "\n",
    "        attention_num = 0\n",
    "        self.conv_l_1 = nn.Sequential(\n",
    "            nn.Conv2d(16, 16, kernel_size=1, bias=False),\n",
    "            nn.BatchNorm2d(16),\n",
    "            nn.ReLU(inplace=True),\n",
    "            BasicBlock(16, 16, 1),\n",
    "            BasicBlock(16, 16, 1),\n",
    "            MultiSpectralChannelSpatialAttentionLayer(c_l[attention_num], c2wh_l[attention_num][0],\n",
    "                                                      c2wh_l[attention_num][1], side='l')  #ty\n",
    "        )\n",
    "\n",
    "        attention_num = 1\n",
    "        self.conv_l_2 = nn.Sequential(\n",
    "            nn.Conv2d(16, 16, kernel_size=1, bias=False),\n",
    "            nn.BatchNorm2d(16),\n",
    "            nn.ReLU(inplace=True),\n",
    "            Bottleneck(16, 16, 2),\n",
    "            MultiSpectralChannelSpatialAttentionLayer(c_l[attention_num], c2wh_l[attention_num][0],\n",
    "                                                      c2wh_l[attention_num][1], side='l')  #ty\n",
    "        )\n",
    "\n",
    "        attention_num = 2\n",
    "        self.conv_l_3 = nn.Sequential(\n",
    "            Bottleneck(64, 32, 1),\n",
    "            Bottleneck(128, 32, 1),\n",
    "            MultiSpectralChannelSpatialAttentionLayer(c_l[attention_num], c2wh_l[attention_num][0],\n",
    "                                                      c2wh_l[attention_num][1], side='l')  #ty\n",
    "        )\n",
    "\n",
    "        attention_num = 3\n",
    "        self.conv_l_4 = nn.Sequential(\n",
    "            nn.Conv2d(128, 128, kernel_size=1, bias=False),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(inplace=True),\n",
    "            Bottleneck(128, 64, 2),\n",
    "            MultiSpectralChannelSpatialAttentionLayer(c_l[attention_num], c2wh_l[attention_num][0],\n",
    "                                                      c2wh_l[attention_num][1], side='l')  #ty\n",
    "        )\n",
    "\n",
    "        attention_num = 4\n",
    "        self.conv_l_5 = nn.Sequential(\n",
    "            nn.Conv2d(256, 256, kernel_size=1, bias=False),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU(inplace=True),\n",
    "            Bottleneck(256, 64, 1),\n",
    "            nn.Conv2d(256, 256, kernel_size=1, bias=False),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU(inplace=True),\n",
    "            Bottleneck(256, 128, 1),\n",
    "            Bottleneck(512, 128, 1),\n",
    "            MultiSpectralChannelSpatialAttentionLayer(c_l[attention_num], c2wh_l[attention_num][0],\n",
    "                                                      c2wh_l[attention_num][1], side='l')  #ty\n",
    "        )\n",
    "\n",
    "        attention_num = 5\n",
    "        self.conv_l_6 = nn.Sequential(\n",
    "            nn.Conv2d(512, 512, kernel_size=1, bias=False),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.ReLU(inplace=True),\n",
    "            Bottleneck(512, 128, 1),\n",
    "            Bottleneck(512, 128, 1),\n",
    "            MultiSpectralChannelSpatialAttentionLayer(c_l[attention_num], c2wh_l[attention_num][0],\n",
    "                                                      c2wh_l[attention_num][1], side='l')  #ty\n",
    "        )\n",
    "\n",
    "        self.conv_l_12 = nn.Conv2d(16, 64, kernel_size=1)\n",
    "        self.conv_l_12_3x3 = nn.Conv2d(64, 64, kernel_size=3, padding=1)\n",
    "        self.conv_l_23 = nn.Conv2d(64, 128, kernel_size=1)\n",
    "        self.conv_l_23_1x1 = nn.Conv2d(128, 128, kernel_size=1)\n",
    "        self.conv_l_34 = nn.Conv2d(128, 256, kernel_size=1)\n",
    "        self.conv_l_34_3x3 = nn.Conv2d(256, 256, kernel_size=3, padding=1)\n",
    "        self.conv_l_45 = nn.Conv2d(256, 512, kernel_size=1)\n",
    "        self.conv_l_45_1x1 = nn.Conv2d(512, 512, kernel_size=1)\n",
    "        self.conv_l_56_1x1 = nn.Conv2d(512, 512, kernel_size=1)\n",
    "\n",
    "        self.bn_l_12 = nn.BatchNorm2d(64)\n",
    "        self.bn_l_23 = nn.BatchNorm2d(128)\n",
    "        self.bn_l_34 = nn.BatchNorm2d(256)\n",
    "        self.bn_l_45 = nn.BatchNorm2d(512)\n",
    "        self.bn_l_56 = nn.BatchNorm2d(512)\n",
    "\n",
    "        self.conv_r_0 = nn.Sequential(\n",
    "            nn.Conv2d(1, 16, kernel_size=7, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(16),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "\n",
    "        attention_num = 0\n",
    "        self.conv_r_1 = nn.Sequential(\n",
    "            nn.Conv2d(16, 16, kernel_size=1, bias=False),\n",
    "            nn.BatchNorm2d(16),\n",
    "            nn.ReLU(inplace=True),\n",
    "            BasicBlock(16, 16, 1),\n",
    "            MultiSpectralChannelSpatialAttentionLayer(c_r[attention_num], c2wh_r[attention_num][0],\n",
    "                                                      c2wh_r[attention_num][1], side='r')  #ty\n",
    "        )\n",
    "\n",
    "        attention_num = 1\n",
    "        self.conv_r_2 = nn.Sequential(\n",
    "            nn.Conv2d(16, 16, kernel_size=1, bias=False),\n",
    "            nn.BatchNorm2d(16),\n",
    "            nn.ReLU(inplace=True),\n",
    "            BasicBlock(16, 16, 1),\n",
    "            MultiSpectralChannelSpatialAttentionLayer(c_r[attention_num], c2wh_r[attention_num][0],\n",
    "                                                      c2wh_r[attention_num][1], side='r')  #ty\n",
    "        )\n",
    "\n",
    "        attention_num = 2\n",
    "        self.conv_r_3 = nn.Sequential(\n",
    "            nn.Conv2d(16, 16, kernel_size=1, bias=False),\n",
    "            nn.BatchNorm2d(16),\n",
    "            nn.ReLU(inplace=True),\n",
    "            BasicBlock(16, 16, 1),\n",
    "            Bottleneck(16, 8, 2),\n",
    "            MultiSpectralChannelSpatialAttentionLayer(c_r[attention_num], c2wh_r[attention_num][0],\n",
    "                                                      c2wh_r[attention_num][1], side='r')  #ty\n",
    "        )\n",
    "\n",
    "        attention_num = 3\n",
    "        self.conv_r_4 = nn.Sequential(\n",
    "            nn.Conv2d(32, 32, kernel_size=1, bias=False),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(inplace=True),\n",
    "            BasicBlock(32, 64, 1),\n",
    "            MultiSpectralChannelSpatialAttentionLayer(c_r[attention_num], c2wh_r[attention_num][0],\n",
    "                                                      c2wh_r[attention_num][1], side='r')  #ty\n",
    "        )\n",
    "\n",
    "        attention_num = 4\n",
    "        self.conv_r_5 = nn.Sequential(\n",
    "            nn.Conv2d(64, 64, kernel_size=1, bias=False),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(inplace=True),\n",
    "            Bottleneck(64, 16, 1),\n",
    "            Bottleneck(64, 16, 1),\n",
    "            Bottleneck(64, 32, 1),\n",
    "            MultiSpectralChannelSpatialAttentionLayer(c_r[attention_num], c2wh_r[attention_num][0],\n",
    "                                                      c2wh_r[attention_num][1], side='r'),  #ty\n",
    "        )\n",
    "\n",
    "        attention_num = 5\n",
    "        self.conv_r_6 = nn.Sequential(\n",
    "            nn.Conv2d(128, 128, kernel_size=1, bias=False),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(inplace=True),\n",
    "            Bottleneck(128, 128, 2),\n",
    "            MultiSpectralChannelSpatialAttentionLayer(c_r[attention_num], c2wh_r[attention_num][0],\n",
    "                                                      c2wh_r[attention_num][1], side='r')  #ty\n",
    "        )\n",
    "\n",
    "        self.conv_r_12_1x1 = nn.Conv2d(16, 16, kernel_size=1)\n",
    "        self.conv_r_23 = nn.Conv2d(16, 32, kernel_size=1)\n",
    "        self.conv_r_23_3x3 = nn.Conv2d(32, 32, kernel_size=3, padding=1)\n",
    "        self.conv_r_34 = nn.Conv2d(32, 64, kernel_size=1)\n",
    "        self.conv_r_34_1x1 = nn.Conv2d(64, 64, kernel_size=1)\n",
    "        self.conv_r_45 = nn.Conv2d(64, 128, kernel_size=1)\n",
    "        self.conv_r_45_1x1 = nn.Conv2d(128, 128, kernel_size=1)\n",
    "        self.conv_r_56 = nn.Conv2d(128, 512, kernel_size=1)\n",
    "        self.conv_r_56_3x3 = nn.Conv2d(512, 512, kernel_size=3, padding=1)\n",
    "\n",
    "        self.bn_r_12 = nn.BatchNorm2d(16)\n",
    "        self.bn_r_23 = nn.BatchNorm2d(32)\n",
    "        self.bn_r_34 = nn.BatchNorm2d(64)\n",
    "        self.bn_r_45 = nn.BatchNorm2d(128)\n",
    "        self.bn_r_56 = nn.BatchNorm2d(512)\n",
    "\n",
    "        self.conv_m_12 = nn.Conv2d(16, 64, kernel_size=1)\n",
    "        self.conv_m_12_1x1 = nn.Conv2d(64, 64, kernel_size=1)\n",
    "        self.conv_m_23 = nn.Conv2d(32, 128, kernel_size=1)\n",
    "        self.conv_m_23_3x3 = nn.Conv2d(128, 128, kernel_size=3, padding=1)\n",
    "        self.conv_m_34 = nn.Conv2d(64, 256, kernel_size=1)\n",
    "        self.conv_m_34_1x1 = nn.Conv2d(256, 256, kernel_size=1)\n",
    "        self.conv_m_45 = nn.Conv2d(128, 512, kernel_size=1)\n",
    "        self.conv_m_45_3x3 = nn.Conv2d(512, 512, kernel_size=3, padding=1)\n",
    "        self.conv_m_56_3x3 = nn.Conv2d(512, 512, kernel_size=3, padding=1)\n",
    "\n",
    "        self.bn_m_12 = nn.BatchNorm2d(64)\n",
    "        self.bn_m_23 = nn.BatchNorm2d(128)\n",
    "        self.bn_m_34 = nn.BatchNorm2d(256)\n",
    "        self.bn_m_45 = nn.BatchNorm2d(512)\n",
    "        self.bn_m_56 = nn.BatchNorm2d(512)\n",
    "\n",
    "        self.conv_f_12 = nn.Conv2d(64, 128, kernel_size=1)\n",
    "        self.conv_f_23 = nn.Conv2d(128, 256, kernel_size=1, stride=2)\n",
    "        self.conv_f_34 = nn.Conv2d(256, 512, kernel_size=1)\n",
    "        self.bn_f_123 = nn.BatchNorm2d(128)\n",
    "        self.bn_f_1234 = nn.BatchNorm2d(256)\n",
    "        self.bn_f_12345 = nn.BatchNorm2d(512)\n",
    "        self.bn_f_123456 = nn.BatchNorm2d(512)\n",
    "        self.conv_f_123_1x1 = nn.Conv2d(128, 128, kernel_size=1)\n",
    "        self.conv_f_1234_1x1 = nn.Conv2d(256, 256, kernel_size=1)\n",
    "        self.conv_f_12345_1x1 = nn.Conv2d(512, 512, kernel_size=1)\n",
    "        self.conv_f_123456_1x1 = nn.Conv2d(512, 512, kernel_size=1)\n",
    "\n",
    "        self.decision_layer = nn.Sequential(\n",
    "            nn.AdaptiveAvgPool2d((1, 1)),\n",
    "            nn.Flatten(),\n",
    "            nn.Dropout(0.1),\n",
    "            nn.Linear(512, 2),\n",
    "        )\n",
    "\n",
    "    def _make_layer(self, out_channels, num_blocks, stride):\n",
    "        strides = [stride] + [1] * (num_blocks - 1)\n",
    "        layers = []\n",
    "        for stride in strides:\n",
    "            layers.append(Bottleneck(self.in_channels, out_channels, stride))\n",
    "            self.in_channels = out_channels * Bottleneck.expansion\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # left\n",
    "        waveform_to_stft = torch.stft(x, n_fft=1024, win_length=50, hop_length=25,\n",
    "                                      window=torch.hann_window(50).cuda(), return_complex=True)\n",
    "        stft_to_stftm = torch.transpose(torch.abs(waveform_to_stft), 1, 2).cuda()\n",
    "        non_trainable_part = self.filterbank_non_trainable_l * self.mask_l\n",
    "        trainable_part = self.filterbank_l * self.inv_mask_l\n",
    "        stftm_to_melgram = torch.matmul(stft_to_stftm, trainable_part + non_trainable_part)\n",
    "        x_l = stftm_to_melgram[:,:100,:].unsqueeze(1)\n",
    "\n",
    "        x_l_0 = self.conv_l_0(x_l)\n",
    "        x_l_1 = self.conv_l_1(x_l_0)\n",
    "        x_l_2 = self.conv_l_2(x_l_1)\n",
    "        x_l_3 = self.conv_l_3(x_l_2)\n",
    "        x_l_4 = self.conv_l_4(x_l_3)\n",
    "        x_l_5 = self.conv_l_5(x_l_4)\n",
    "        x_l_6 = self.conv_l_6(x_l_5)\n",
    "\n",
    "        x_l_12 = F.relu(self.bn_l_12(\n",
    "            self.conv_l_12_3x3(self.conv_l_12(x_l_1) + F.interpolate(x_l_2, scale_factor=2, mode='nearest'))),\n",
    "            inplace=True)\n",
    "        x_l_23 = F.relu(self.bn_l_23(self.conv_l_23_1x1(self.conv_l_23(x_l_2) + x_l_3)), inplace=True)\n",
    "        x_l_34 = F.relu(self.bn_l_34(\n",
    "            self.conv_l_34_3x3(self.conv_l_34(x_l_3) + F.interpolate(x_l_4, scale_factor=2, mode='nearest'))),\n",
    "            inplace=True)\n",
    "        x_l_45 = F.relu(self.bn_l_45(self.conv_l_45_1x1(self.conv_l_45(x_l_4) + x_l_5)), inplace=True)\n",
    "        x_l_56 = F.relu(self.bn_l_56(self.conv_l_56_1x1(x_l_5 + x_l_6)), inplace=True)\n",
    "        \n",
    "        # right\n",
    "        waveform_to_stft = torch.stft(x, n_fft=1024, win_length=50, hop_length=25,\n",
    "                                      window=torch.hann_window(50).cuda(), return_complex=True)\n",
    "        stft_to_stftm = torch.transpose(torch.abs(waveform_to_stft), 1, 2).cuda()\n",
    "        non_trainable_part = self.filterbank_non_trainable_r * self.mask_r\n",
    "        trainable_part = self.filterbank_r * self.inv_mask_r\n",
    "        stftm_to_melgram = torch.matmul(stft_to_stftm, trainable_part + non_trainable_part)\n",
    "        x_r = stftm_to_melgram[:,:100,:].unsqueeze(1)\n",
    "\n",
    "        x_r_0 = self.conv_r_0(x_r)\n",
    "        x_r_1 = self.conv_r_1(x_r_0)\n",
    "        x_r_2 = self.conv_r_2(x_r_1)\n",
    "        x_r_3 = self.conv_r_3(x_r_2)\n",
    "        x_r_4 = self.conv_r_4(x_r_3)\n",
    "        x_r_5 = self.conv_r_5(x_r_4)\n",
    "        x_r_6 = self.conv_r_6(x_r_5)\n",
    "\n",
    "        x_r_12 = F.relu(self.bn_r_12(self.conv_r_12_1x1(x_r_1 + x_r_2)), inplace=True)\n",
    "        x_r_23 = F.relu(self.bn_r_23(\n",
    "            self.conv_r_23_3x3(self.conv_r_23(x_r_2) + F.interpolate(x_r_3, scale_factor=2, mode='nearest'))),\n",
    "            inplace=True)\n",
    "        x_r_34 = F.relu(self.bn_r_34(self.conv_r_34_1x1(self.conv_r_34(x_r_3) + x_r_4)), inplace=True)\n",
    "        x_r_45 = F.relu(self.bn_r_45(self.conv_r_45_1x1(self.conv_r_45(x_r_4) + x_r_5)), inplace=True)\n",
    "        x_r_56 = F.relu(self.bn_r_56(\n",
    "            self.conv_r_56_3x3(self.conv_r_56(x_r_5) + F.interpolate(x_r_6, scale_factor=2, mode='nearest'))),\n",
    "            inplace=True)\n",
    "        \n",
    "        # fusion\n",
    "        x_m_12 = F.relu(self.bn_m_12(self.conv_m_12_1x1(x_l_12 + self.conv_m_12(x_r_12))), inplace=True)\n",
    "        x_m_23 = F.relu(self.bn_m_23(\n",
    "            self.conv_m_23_3x3(F.interpolate(x_l_23, scale_factor=2, mode='nearest') + self.conv_m_23(x_r_23))),\n",
    "            inplace=True)\n",
    "        x_m_34 = F.relu(self.bn_m_34(self.conv_m_34_1x1(x_l_34 + self.conv_m_34(x_r_34))), inplace=True)\n",
    "        x_m_45 = F.relu(self.bn_m_45(\n",
    "            self.conv_m_45_3x3(F.interpolate(x_l_45, scale_factor=2, mode='nearest') + self.conv_m_45(x_r_45))),\n",
    "            inplace=True)\n",
    "        x_m_56 = F.relu(\n",
    "            self.bn_m_56(self.conv_m_56_3x3(F.interpolate(x_l_56, scale_factor=2, mode='nearest') + x_r_56)),\n",
    "            inplace=True)\n",
    "\n",
    "        x_f_123 = F.relu(self.bn_f_123(self.conv_f_123_1x1(self.conv_f_12(x_m_12) + x_m_23)), inplace=True)\n",
    "        x_f_1234 = F.relu(self.bn_f_1234(self.conv_f_1234_1x1(self.conv_f_23(x_f_123) + x_m_34)), inplace=True)\n",
    "        x_f_12345 = F.relu(self.bn_f_12345(self.conv_f_12345_1x1(self.conv_f_34(x_f_1234) + x_m_45)), inplace=True)\n",
    "        x_f_123456 = F.relu(self.bn_f_123456(self.conv_f_123456_1x1((x_f_12345 + x_m_56))), inplace=True)\n",
    "        x= self.decision_layer(x_f_123456)\n",
    "\n",
    "        return x\n",
    "    "
   ],
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-11T07:09:12.156666Z",
     "start_time": "2025-04-11T07:09:10.553051Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from torchinfo import summary\n",
    "\n",
    "summary(ZHJNet().cuda(), input_size=(1, 2540))"
   ],
   "id": "acea4c203093e187",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "left cuda:0 cuda:0\n",
      "right cuda:0 cuda:0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "==============================================================================================================\n",
       "Layer (type:depth-idx)                                       Output Shape              Param #\n",
       "==============================================================================================================\n",
       "ZHJNet                                                       [1, 2]                    41,040\n",
       "├─Sequential: 1-1                                            [1, 16, 96, 36]           --\n",
       "│    └─Conv2d: 2-1                                           [1, 16, 96, 36]           784\n",
       "│    └─BatchNorm2d: 2-2                                      [1, 16, 96, 36]           32\n",
       "│    └─ReLU: 2-3                                             [1, 16, 96, 36]           --\n",
       "├─Sequential: 1-2                                            [1, 16, 96, 36]           --\n",
       "│    └─Conv2d: 2-4                                           [1, 16, 96, 36]           256\n",
       "│    └─BatchNorm2d: 2-5                                      [1, 16, 96, 36]           32\n",
       "│    └─ReLU: 2-6                                             [1, 16, 96, 36]           --\n",
       "│    └─BasicBlock: 2-7                                       [1, 16, 96, 36]           --\n",
       "│    │    └─Conv2d: 3-1                                      [1, 16, 96, 36]           2,304\n",
       "│    │    └─BatchNorm2d: 3-2                                 [1, 16, 96, 36]           32\n",
       "│    │    └─ReLU: 3-3                                        [1, 16, 96, 36]           --\n",
       "│    │    └─Conv2d: 3-4                                      [1, 16, 96, 36]           2,304\n",
       "│    │    └─BatchNorm2d: 3-5                                 [1, 16, 96, 36]           32\n",
       "│    │    └─Sequential: 3-6                                  [1, 16, 96, 36]           --\n",
       "│    │    └─ReLU: 3-7                                        [1, 16, 96, 36]           --\n",
       "│    └─BasicBlock: 2-8                                       [1, 16, 96, 36]           --\n",
       "│    │    └─Conv2d: 3-8                                      [1, 16, 96, 36]           2,304\n",
       "│    │    └─BatchNorm2d: 3-9                                 [1, 16, 96, 36]           32\n",
       "│    │    └─ReLU: 3-10                                       [1, 16, 96, 36]           --\n",
       "│    │    └─Conv2d: 3-11                                     [1, 16, 96, 36]           2,304\n",
       "│    │    └─BatchNorm2d: 3-12                                [1, 16, 96, 36]           32\n",
       "│    │    └─Sequential: 3-13                                 [1, 16, 96, 36]           --\n",
       "│    │    └─ReLU: 3-14                                       [1, 16, 96, 36]           --\n",
       "│    └─MultiSpectralChannelSpatialAttentionLayer: 2-9        [1, 16, 96, 36]           --\n",
       "│    │    └─MultiSpectralDCTLayer: 3-15                      [1, 16]                   --\n",
       "│    │    └─Sequential: 3-16                                 [1, 16]                   32\n",
       "│    │    └─SpatialAttention: 3-17                           [1, 16, 96, 36]           99\n",
       "├─Sequential: 1-3                                            [1, 64, 48, 18]           --\n",
       "│    └─Conv2d: 2-10                                          [1, 16, 96, 36]           256\n",
       "│    └─BatchNorm2d: 2-11                                     [1, 16, 96, 36]           32\n",
       "│    └─ReLU: 2-12                                            [1, 16, 96, 36]           --\n",
       "│    └─Bottleneck: 2-13                                      [1, 64, 48, 18]           --\n",
       "│    │    └─Conv2d: 3-18                                     [1, 16, 96, 36]           256\n",
       "│    │    └─BatchNorm2d: 3-19                                [1, 16, 96, 36]           32\n",
       "│    │    └─ReLU: 3-20                                       [1, 16, 96, 36]           --\n",
       "│    │    └─Conv2d: 3-21                                     [1, 16, 48, 18]           2,304\n",
       "│    │    └─BatchNorm2d: 3-22                                [1, 16, 48, 18]           32\n",
       "│    │    └─ReLU: 3-23                                       [1, 16, 48, 18]           --\n",
       "│    │    └─Conv2d: 3-24                                     [1, 64, 48, 18]           1,024\n",
       "│    │    └─BatchNorm2d: 3-25                                [1, 64, 48, 18]           128\n",
       "│    │    └─Sequential: 3-26                                 [1, 64, 48, 18]           1,152\n",
       "│    │    └─ReLU: 3-27                                       [1, 64, 48, 18]           --\n",
       "│    └─MultiSpectralChannelSpatialAttentionLayer: 2-14       [1, 64, 48, 18]           --\n",
       "│    │    └─MultiSpectralDCTLayer: 3-28                      [1, 64]                   --\n",
       "│    │    └─Sequential: 3-29                                 [1, 64]                   512\n",
       "│    │    └─SpatialAttention: 3-30                           [1, 64, 48, 18]           99\n",
       "├─Sequential: 1-4                                            [1, 128, 48, 18]          --\n",
       "│    └─Bottleneck: 2-15                                      [1, 128, 48, 18]          --\n",
       "│    │    └─Conv2d: 3-31                                     [1, 32, 48, 18]           2,048\n",
       "│    │    └─BatchNorm2d: 3-32                                [1, 32, 48, 18]           64\n",
       "│    │    └─ReLU: 3-33                                       [1, 32, 48, 18]           --\n",
       "│    │    └─Conv2d: 3-34                                     [1, 32, 48, 18]           9,216\n",
       "│    │    └─BatchNorm2d: 3-35                                [1, 32, 48, 18]           64\n",
       "│    │    └─ReLU: 3-36                                       [1, 32, 48, 18]           --\n",
       "│    │    └─Conv2d: 3-37                                     [1, 128, 48, 18]          4,096\n",
       "│    │    └─BatchNorm2d: 3-38                                [1, 128, 48, 18]          256\n",
       "│    │    └─Sequential: 3-39                                 [1, 128, 48, 18]          8,448\n",
       "│    │    └─ReLU: 3-40                                       [1, 128, 48, 18]          --\n",
       "│    └─Bottleneck: 2-16                                      [1, 128, 48, 18]          --\n",
       "│    │    └─Conv2d: 3-41                                     [1, 32, 48, 18]           4,096\n",
       "│    │    └─BatchNorm2d: 3-42                                [1, 32, 48, 18]           64\n",
       "│    │    └─ReLU: 3-43                                       [1, 32, 48, 18]           --\n",
       "│    │    └─Conv2d: 3-44                                     [1, 32, 48, 18]           9,216\n",
       "│    │    └─BatchNorm2d: 3-45                                [1, 32, 48, 18]           64\n",
       "│    │    └─ReLU: 3-46                                       [1, 32, 48, 18]           --\n",
       "│    │    └─Conv2d: 3-47                                     [1, 128, 48, 18]          4,096\n",
       "│    │    └─BatchNorm2d: 3-48                                [1, 128, 48, 18]          256\n",
       "│    │    └─Sequential: 3-49                                 [1, 128, 48, 18]          --\n",
       "│    │    └─ReLU: 3-50                                       [1, 128, 48, 18]          --\n",
       "│    └─MultiSpectralChannelSpatialAttentionLayer: 2-17       [1, 128, 48, 18]          --\n",
       "│    │    └─MultiSpectralDCTLayer: 3-51                      [1, 128]                  --\n",
       "│    │    └─Sequential: 3-52                                 [1, 128]                  2,048\n",
       "│    │    └─SpatialAttention: 3-53                           [1, 128, 48, 18]          99\n",
       "├─Sequential: 1-5                                            [1, 256, 24, 9]           --\n",
       "│    └─Conv2d: 2-18                                          [1, 128, 48, 18]          16,384\n",
       "│    └─BatchNorm2d: 2-19                                     [1, 128, 48, 18]          256\n",
       "│    └─ReLU: 2-20                                            [1, 128, 48, 18]          --\n",
       "│    └─Bottleneck: 2-21                                      [1, 256, 24, 9]           --\n",
       "│    │    └─Conv2d: 3-54                                     [1, 64, 48, 18]           8,192\n",
       "│    │    └─BatchNorm2d: 3-55                                [1, 64, 48, 18]           128\n",
       "│    │    └─ReLU: 3-56                                       [1, 64, 48, 18]           --\n",
       "│    │    └─Conv2d: 3-57                                     [1, 64, 24, 9]            36,864\n",
       "│    │    └─BatchNorm2d: 3-58                                [1, 64, 24, 9]            128\n",
       "│    │    └─ReLU: 3-59                                       [1, 64, 24, 9]            --\n",
       "│    │    └─Conv2d: 3-60                                     [1, 256, 24, 9]           16,384\n",
       "│    │    └─BatchNorm2d: 3-61                                [1, 256, 24, 9]           512\n",
       "│    │    └─Sequential: 3-62                                 [1, 256, 24, 9]           33,280\n",
       "│    │    └─ReLU: 3-63                                       [1, 256, 24, 9]           --\n",
       "│    └─MultiSpectralChannelSpatialAttentionLayer: 2-22       [1, 256, 24, 9]           --\n",
       "│    │    └─MultiSpectralDCTLayer: 3-64                      [1, 256]                  --\n",
       "│    │    └─Sequential: 3-65                                 [1, 256]                  8,192\n",
       "│    │    └─SpatialAttention: 3-66                           [1, 256, 24, 9]           99\n",
       "├─Sequential: 1-6                                            [1, 512, 24, 9]           --\n",
       "│    └─Conv2d: 2-23                                          [1, 256, 24, 9]           65,536\n",
       "│    └─BatchNorm2d: 2-24                                     [1, 256, 24, 9]           512\n",
       "│    └─ReLU: 2-25                                            [1, 256, 24, 9]           --\n",
       "│    └─Bottleneck: 2-26                                      [1, 256, 24, 9]           --\n",
       "│    │    └─Conv2d: 3-67                                     [1, 64, 24, 9]            16,384\n",
       "│    │    └─BatchNorm2d: 3-68                                [1, 64, 24, 9]            128\n",
       "│    │    └─ReLU: 3-69                                       [1, 64, 24, 9]            --\n",
       "│    │    └─Conv2d: 3-70                                     [1, 64, 24, 9]            36,864\n",
       "│    │    └─BatchNorm2d: 3-71                                [1, 64, 24, 9]            128\n",
       "│    │    └─ReLU: 3-72                                       [1, 64, 24, 9]            --\n",
       "│    │    └─Conv2d: 3-73                                     [1, 256, 24, 9]           16,384\n",
       "│    │    └─BatchNorm2d: 3-74                                [1, 256, 24, 9]           512\n",
       "│    │    └─Sequential: 3-75                                 [1, 256, 24, 9]           --\n",
       "│    │    └─ReLU: 3-76                                       [1, 256, 24, 9]           --\n",
       "│    └─Conv2d: 2-27                                          [1, 256, 24, 9]           65,536\n",
       "│    └─BatchNorm2d: 2-28                                     [1, 256, 24, 9]           512\n",
       "│    └─ReLU: 2-29                                            [1, 256, 24, 9]           --\n",
       "│    └─Bottleneck: 2-30                                      [1, 512, 24, 9]           --\n",
       "│    │    └─Conv2d: 3-77                                     [1, 128, 24, 9]           32,768\n",
       "│    │    └─BatchNorm2d: 3-78                                [1, 128, 24, 9]           256\n",
       "│    │    └─ReLU: 3-79                                       [1, 128, 24, 9]           --\n",
       "│    │    └─Conv2d: 3-80                                     [1, 128, 24, 9]           147,456\n",
       "│    │    └─BatchNorm2d: 3-81                                [1, 128, 24, 9]           256\n",
       "│    │    └─ReLU: 3-82                                       [1, 128, 24, 9]           --\n",
       "│    │    └─Conv2d: 3-83                                     [1, 512, 24, 9]           65,536\n",
       "│    │    └─BatchNorm2d: 3-84                                [1, 512, 24, 9]           1,024\n",
       "│    │    └─Sequential: 3-85                                 [1, 512, 24, 9]           132,096\n",
       "│    │    └─ReLU: 3-86                                       [1, 512, 24, 9]           --\n",
       "│    └─Bottleneck: 2-31                                      [1, 512, 24, 9]           --\n",
       "│    │    └─Conv2d: 3-87                                     [1, 128, 24, 9]           65,536\n",
       "│    │    └─BatchNorm2d: 3-88                                [1, 128, 24, 9]           256\n",
       "│    │    └─ReLU: 3-89                                       [1, 128, 24, 9]           --\n",
       "│    │    └─Conv2d: 3-90                                     [1, 128, 24, 9]           147,456\n",
       "│    │    └─BatchNorm2d: 3-91                                [1, 128, 24, 9]           256\n",
       "│    │    └─ReLU: 3-92                                       [1, 128, 24, 9]           --\n",
       "│    │    └─Conv2d: 3-93                                     [1, 512, 24, 9]           65,536\n",
       "│    │    └─BatchNorm2d: 3-94                                [1, 512, 24, 9]           1,024\n",
       "│    │    └─Sequential: 3-95                                 [1, 512, 24, 9]           --\n",
       "│    │    └─ReLU: 3-96                                       [1, 512, 24, 9]           --\n",
       "│    └─MultiSpectralChannelSpatialAttentionLayer: 2-32       [1, 512, 24, 9]           --\n",
       "│    │    └─MultiSpectralDCTLayer: 3-97                      [1, 512]                  --\n",
       "│    │    └─Sequential: 3-98                                 [1, 512]                  32,768\n",
       "│    │    └─SpatialAttention: 3-99                           [1, 512, 24, 9]           99\n",
       "├─Sequential: 1-7                                            [1, 512, 24, 9]           --\n",
       "│    └─Conv2d: 2-33                                          [1, 512, 24, 9]           262,144\n",
       "│    └─BatchNorm2d: 2-34                                     [1, 512, 24, 9]           1,024\n",
       "│    └─ReLU: 2-35                                            [1, 512, 24, 9]           --\n",
       "│    └─Bottleneck: 2-36                                      [1, 512, 24, 9]           --\n",
       "│    │    └─Conv2d: 3-100                                    [1, 128, 24, 9]           65,536\n",
       "│    │    └─BatchNorm2d: 3-101                               [1, 128, 24, 9]           256\n",
       "│    │    └─ReLU: 3-102                                      [1, 128, 24, 9]           --\n",
       "│    │    └─Conv2d: 3-103                                    [1, 128, 24, 9]           147,456\n",
       "│    │    └─BatchNorm2d: 3-104                               [1, 128, 24, 9]           256\n",
       "│    │    └─ReLU: 3-105                                      [1, 128, 24, 9]           --\n",
       "│    │    └─Conv2d: 3-106                                    [1, 512, 24, 9]           65,536\n",
       "│    │    └─BatchNorm2d: 3-107                               [1, 512, 24, 9]           1,024\n",
       "│    │    └─Sequential: 3-108                                [1, 512, 24, 9]           --\n",
       "│    │    └─ReLU: 3-109                                      [1, 512, 24, 9]           --\n",
       "│    └─Bottleneck: 2-37                                      [1, 512, 24, 9]           --\n",
       "│    │    └─Conv2d: 3-110                                    [1, 128, 24, 9]           65,536\n",
       "│    │    └─BatchNorm2d: 3-111                               [1, 128, 24, 9]           256\n",
       "│    │    └─ReLU: 3-112                                      [1, 128, 24, 9]           --\n",
       "│    │    └─Conv2d: 3-113                                    [1, 128, 24, 9]           147,456\n",
       "│    │    └─BatchNorm2d: 3-114                               [1, 128, 24, 9]           256\n",
       "│    │    └─ReLU: 3-115                                      [1, 128, 24, 9]           --\n",
       "│    │    └─Conv2d: 3-116                                    [1, 512, 24, 9]           65,536\n",
       "│    │    └─BatchNorm2d: 3-117                               [1, 512, 24, 9]           1,024\n",
       "│    │    └─Sequential: 3-118                                [1, 512, 24, 9]           --\n",
       "│    │    └─ReLU: 3-119                                      [1, 512, 24, 9]           --\n",
       "│    └─MultiSpectralChannelSpatialAttentionLayer: 2-38       [1, 512, 24, 9]           --\n",
       "│    │    └─MultiSpectralDCTLayer: 3-120                     [1, 512]                  --\n",
       "│    │    └─Sequential: 3-121                                [1, 512]                  32,768\n",
       "│    │    └─SpatialAttention: 3-122                          [1, 512, 24, 9]           99\n",
       "├─Conv2d: 1-8                                                [1, 64, 96, 36]           1,088\n",
       "├─Conv2d: 1-9                                                [1, 64, 96, 36]           36,928\n",
       "├─BatchNorm2d: 1-10                                          [1, 64, 96, 36]           128\n",
       "├─Conv2d: 1-11                                               [1, 128, 48, 18]          8,320\n",
       "├─Conv2d: 1-12                                               [1, 128, 48, 18]          16,512\n",
       "├─BatchNorm2d: 1-13                                          [1, 128, 48, 18]          256\n",
       "├─Conv2d: 1-14                                               [1, 256, 48, 18]          33,024\n",
       "├─Conv2d: 1-15                                               [1, 256, 48, 18]          590,080\n",
       "├─BatchNorm2d: 1-16                                          [1, 256, 48, 18]          512\n",
       "├─Conv2d: 1-17                                               [1, 512, 24, 9]           131,584\n",
       "├─Conv2d: 1-18                                               [1, 512, 24, 9]           262,656\n",
       "├─BatchNorm2d: 1-19                                          [1, 512, 24, 9]           1,024\n",
       "├─Conv2d: 1-20                                               [1, 512, 24, 9]           262,656\n",
       "├─BatchNorm2d: 1-21                                          [1, 512, 24, 9]           1,024\n",
       "├─Sequential: 1-22                                           [1, 16, 96, 36]           --\n",
       "│    └─Conv2d: 2-39                                          [1, 16, 96, 36]           784\n",
       "│    └─BatchNorm2d: 2-40                                     [1, 16, 96, 36]           32\n",
       "│    └─ReLU: 2-41                                            [1, 16, 96, 36]           --\n",
       "├─Sequential: 1-23                                           [1, 16, 96, 36]           --\n",
       "│    └─Conv2d: 2-42                                          [1, 16, 96, 36]           256\n",
       "│    └─BatchNorm2d: 2-43                                     [1, 16, 96, 36]           32\n",
       "│    └─ReLU: 2-44                                            [1, 16, 96, 36]           --\n",
       "│    └─BasicBlock: 2-45                                      [1, 16, 96, 36]           --\n",
       "│    │    └─Conv2d: 3-123                                    [1, 16, 96, 36]           2,304\n",
       "│    │    └─BatchNorm2d: 3-124                               [1, 16, 96, 36]           32\n",
       "│    │    └─ReLU: 3-125                                      [1, 16, 96, 36]           --\n",
       "│    │    └─Conv2d: 3-126                                    [1, 16, 96, 36]           2,304\n",
       "│    │    └─BatchNorm2d: 3-127                               [1, 16, 96, 36]           32\n",
       "│    │    └─Sequential: 3-128                                [1, 16, 96, 36]           --\n",
       "│    │    └─ReLU: 3-129                                      [1, 16, 96, 36]           --\n",
       "│    └─MultiSpectralChannelSpatialAttentionLayer: 2-46       [1, 16, 96, 36]           --\n",
       "│    │    └─MultiSpectralDCTLayer: 3-130                     [1, 16]                   --\n",
       "│    │    └─Sequential: 3-131                                [1, 16]                   32\n",
       "│    │    └─SpatialAttention: 3-132                          [1, 16, 96, 36]           99\n",
       "├─Sequential: 1-24                                           [1, 16, 96, 36]           --\n",
       "│    └─Conv2d: 2-47                                          [1, 16, 96, 36]           256\n",
       "│    └─BatchNorm2d: 2-48                                     [1, 16, 96, 36]           32\n",
       "│    └─ReLU: 2-49                                            [1, 16, 96, 36]           --\n",
       "│    └─BasicBlock: 2-50                                      [1, 16, 96, 36]           --\n",
       "│    │    └─Conv2d: 3-133                                    [1, 16, 96, 36]           2,304\n",
       "│    │    └─BatchNorm2d: 3-134                               [1, 16, 96, 36]           32\n",
       "│    │    └─ReLU: 3-135                                      [1, 16, 96, 36]           --\n",
       "│    │    └─Conv2d: 3-136                                    [1, 16, 96, 36]           2,304\n",
       "│    │    └─BatchNorm2d: 3-137                               [1, 16, 96, 36]           32\n",
       "│    │    └─Sequential: 3-138                                [1, 16, 96, 36]           --\n",
       "│    │    └─ReLU: 3-139                                      [1, 16, 96, 36]           --\n",
       "│    └─MultiSpectralChannelSpatialAttentionLayer: 2-51       [1, 16, 96, 36]           --\n",
       "│    │    └─MultiSpectralDCTLayer: 3-140                     [1, 16]                   --\n",
       "│    │    └─Sequential: 3-141                                [1, 16]                   32\n",
       "│    │    └─SpatialAttention: 3-142                          [1, 16, 96, 36]           99\n",
       "├─Sequential: 1-25                                           [1, 32, 48, 18]           --\n",
       "│    └─Conv2d: 2-52                                          [1, 16, 96, 36]           256\n",
       "│    └─BatchNorm2d: 2-53                                     [1, 16, 96, 36]           32\n",
       "│    └─ReLU: 2-54                                            [1, 16, 96, 36]           --\n",
       "│    └─BasicBlock: 2-55                                      [1, 16, 96, 36]           --\n",
       "│    │    └─Conv2d: 3-143                                    [1, 16, 96, 36]           2,304\n",
       "│    │    └─BatchNorm2d: 3-144                               [1, 16, 96, 36]           32\n",
       "│    │    └─ReLU: 3-145                                      [1, 16, 96, 36]           --\n",
       "│    │    └─Conv2d: 3-146                                    [1, 16, 96, 36]           2,304\n",
       "│    │    └─BatchNorm2d: 3-147                               [1, 16, 96, 36]           32\n",
       "│    │    └─Sequential: 3-148                                [1, 16, 96, 36]           --\n",
       "│    │    └─ReLU: 3-149                                      [1, 16, 96, 36]           --\n",
       "│    └─Bottleneck: 2-56                                      [1, 32, 48, 18]           --\n",
       "│    │    └─Conv2d: 3-150                                    [1, 8, 96, 36]            128\n",
       "│    │    └─BatchNorm2d: 3-151                               [1, 8, 96, 36]            16\n",
       "│    │    └─ReLU: 3-152                                      [1, 8, 96, 36]            --\n",
       "│    │    └─Conv2d: 3-153                                    [1, 8, 48, 18]            576\n",
       "│    │    └─BatchNorm2d: 3-154                               [1, 8, 48, 18]            16\n",
       "│    │    └─ReLU: 3-155                                      [1, 8, 48, 18]            --\n",
       "│    │    └─Conv2d: 3-156                                    [1, 32, 48, 18]           256\n",
       "│    │    └─BatchNorm2d: 3-157                               [1, 32, 48, 18]           64\n",
       "│    │    └─Sequential: 3-158                                [1, 32, 48, 18]           576\n",
       "│    │    └─ReLU: 3-159                                      [1, 32, 48, 18]           --\n",
       "│    └─MultiSpectralChannelSpatialAttentionLayer: 2-57       [1, 32, 48, 18]           --\n",
       "│    │    └─MultiSpectralDCTLayer: 3-160                     [1, 32]                   --\n",
       "│    │    └─Sequential: 3-161                                [1, 32]                   128\n",
       "│    │    └─SpatialAttention: 3-162                          [1, 32, 48, 18]           99\n",
       "├─Sequential: 1-26                                           [1, 64, 48, 18]           --\n",
       "│    └─Conv2d: 2-58                                          [1, 32, 48, 18]           1,024\n",
       "│    └─BatchNorm2d: 2-59                                     [1, 32, 48, 18]           64\n",
       "│    └─ReLU: 2-60                                            [1, 32, 48, 18]           --\n",
       "│    └─BasicBlock: 2-61                                      [1, 64, 48, 18]           --\n",
       "│    │    └─Conv2d: 3-163                                    [1, 64, 48, 18]           18,432\n",
       "│    │    └─BatchNorm2d: 3-164                               [1, 64, 48, 18]           128\n",
       "│    │    └─ReLU: 3-165                                      [1, 64, 48, 18]           --\n",
       "│    │    └─Conv2d: 3-166                                    [1, 64, 48, 18]           36,864\n",
       "│    │    └─BatchNorm2d: 3-167                               [1, 64, 48, 18]           128\n",
       "│    │    └─Sequential: 3-168                                [1, 64, 48, 18]           2,176\n",
       "│    │    └─ReLU: 3-169                                      [1, 64, 48, 18]           --\n",
       "│    └─MultiSpectralChannelSpatialAttentionLayer: 2-62       [1, 64, 48, 18]           --\n",
       "│    │    └─MultiSpectralDCTLayer: 3-170                     [1, 64]                   --\n",
       "│    │    └─Sequential: 3-171                                [1, 64]                   512\n",
       "│    │    └─SpatialAttention: 3-172                          [1, 64, 48, 18]           99\n",
       "├─Sequential: 1-27                                           [1, 128, 48, 18]          --\n",
       "│    └─Conv2d: 2-63                                          [1, 64, 48, 18]           4,096\n",
       "│    └─BatchNorm2d: 2-64                                     [1, 64, 48, 18]           128\n",
       "│    └─ReLU: 2-65                                            [1, 64, 48, 18]           --\n",
       "│    └─Bottleneck: 2-66                                      [1, 64, 48, 18]           --\n",
       "│    │    └─Conv2d: 3-173                                    [1, 16, 48, 18]           1,024\n",
       "│    │    └─BatchNorm2d: 3-174                               [1, 16, 48, 18]           32\n",
       "│    │    └─ReLU: 3-175                                      [1, 16, 48, 18]           --\n",
       "│    │    └─Conv2d: 3-176                                    [1, 16, 48, 18]           2,304\n",
       "│    │    └─BatchNorm2d: 3-177                               [1, 16, 48, 18]           32\n",
       "│    │    └─ReLU: 3-178                                      [1, 16, 48, 18]           --\n",
       "│    │    └─Conv2d: 3-179                                    [1, 64, 48, 18]           1,024\n",
       "│    │    └─BatchNorm2d: 3-180                               [1, 64, 48, 18]           128\n",
       "│    │    └─Sequential: 3-181                                [1, 64, 48, 18]           --\n",
       "│    │    └─ReLU: 3-182                                      [1, 64, 48, 18]           --\n",
       "│    └─Bottleneck: 2-67                                      [1, 64, 48, 18]           --\n",
       "│    │    └─Conv2d: 3-183                                    [1, 16, 48, 18]           1,024\n",
       "│    │    └─BatchNorm2d: 3-184                               [1, 16, 48, 18]           32\n",
       "│    │    └─ReLU: 3-185                                      [1, 16, 48, 18]           --\n",
       "│    │    └─Conv2d: 3-186                                    [1, 16, 48, 18]           2,304\n",
       "│    │    └─BatchNorm2d: 3-187                               [1, 16, 48, 18]           32\n",
       "│    │    └─ReLU: 3-188                                      [1, 16, 48, 18]           --\n",
       "│    │    └─Conv2d: 3-189                                    [1, 64, 48, 18]           1,024\n",
       "│    │    └─BatchNorm2d: 3-190                               [1, 64, 48, 18]           128\n",
       "│    │    └─Sequential: 3-191                                [1, 64, 48, 18]           --\n",
       "│    │    └─ReLU: 3-192                                      [1, 64, 48, 18]           --\n",
       "│    └─Bottleneck: 2-68                                      [1, 128, 48, 18]          --\n",
       "│    │    └─Conv2d: 3-193                                    [1, 32, 48, 18]           2,048\n",
       "│    │    └─BatchNorm2d: 3-194                               [1, 32, 48, 18]           64\n",
       "│    │    └─ReLU: 3-195                                      [1, 32, 48, 18]           --\n",
       "│    │    └─Conv2d: 3-196                                    [1, 32, 48, 18]           9,216\n",
       "│    │    └─BatchNorm2d: 3-197                               [1, 32, 48, 18]           64\n",
       "│    │    └─ReLU: 3-198                                      [1, 32, 48, 18]           --\n",
       "│    │    └─Conv2d: 3-199                                    [1, 128, 48, 18]          4,096\n",
       "│    │    └─BatchNorm2d: 3-200                               [1, 128, 48, 18]          256\n",
       "│    │    └─Sequential: 3-201                                [1, 128, 48, 18]          8,448\n",
       "│    │    └─ReLU: 3-202                                      [1, 128, 48, 18]          --\n",
       "│    └─MultiSpectralChannelSpatialAttentionLayer: 2-69       [1, 128, 48, 18]          --\n",
       "│    │    └─MultiSpectralDCTLayer: 3-203                     [1, 128]                  --\n",
       "│    │    └─Sequential: 3-204                                [1, 128]                  2,048\n",
       "│    │    └─SpatialAttention: 3-205                          [1, 128, 48, 18]          99\n",
       "├─Sequential: 1-28                                           [1, 512, 24, 9]           --\n",
       "│    └─Conv2d: 2-70                                          [1, 128, 48, 18]          16,384\n",
       "│    └─BatchNorm2d: 2-71                                     [1, 128, 48, 18]          256\n",
       "│    └─ReLU: 2-72                                            [1, 128, 48, 18]          --\n",
       "│    └─Bottleneck: 2-73                                      [1, 512, 24, 9]           --\n",
       "│    │    └─Conv2d: 3-206                                    [1, 128, 48, 18]          16,384\n",
       "│    │    └─BatchNorm2d: 3-207                               [1, 128, 48, 18]          256\n",
       "│    │    └─ReLU: 3-208                                      [1, 128, 48, 18]          --\n",
       "│    │    └─Conv2d: 3-209                                    [1, 128, 24, 9]           147,456\n",
       "│    │    └─BatchNorm2d: 3-210                               [1, 128, 24, 9]           256\n",
       "│    │    └─ReLU: 3-211                                      [1, 128, 24, 9]           --\n",
       "│    │    └─Conv2d: 3-212                                    [1, 512, 24, 9]           65,536\n",
       "│    │    └─BatchNorm2d: 3-213                               [1, 512, 24, 9]           1,024\n",
       "│    │    └─Sequential: 3-214                                [1, 512, 24, 9]           66,560\n",
       "│    │    └─ReLU: 3-215                                      [1, 512, 24, 9]           --\n",
       "│    └─MultiSpectralChannelSpatialAttentionLayer: 2-74       [1, 512, 24, 9]           --\n",
       "│    │    └─MultiSpectralDCTLayer: 3-216                     [1, 512]                  --\n",
       "│    │    └─Sequential: 3-217                                [1, 512]                  32,768\n",
       "│    │    └─SpatialAttention: 3-218                          [1, 512, 24, 9]           99\n",
       "├─Conv2d: 1-29                                               [1, 16, 96, 36]           272\n",
       "├─BatchNorm2d: 1-30                                          [1, 16, 96, 36]           32\n",
       "├─Conv2d: 1-31                                               [1, 32, 96, 36]           544\n",
       "├─Conv2d: 1-32                                               [1, 32, 96, 36]           9,248\n",
       "├─BatchNorm2d: 1-33                                          [1, 32, 96, 36]           64\n",
       "├─Conv2d: 1-34                                               [1, 64, 48, 18]           2,112\n",
       "├─Conv2d: 1-35                                               [1, 64, 48, 18]           4,160\n",
       "├─BatchNorm2d: 1-36                                          [1, 64, 48, 18]           128\n",
       "├─Conv2d: 1-37                                               [1, 128, 48, 18]          8,320\n",
       "├─Conv2d: 1-38                                               [1, 128, 48, 18]          16,512\n",
       "├─BatchNorm2d: 1-39                                          [1, 128, 48, 18]          256\n",
       "├─Conv2d: 1-40                                               [1, 512, 48, 18]          66,048\n",
       "├─Conv2d: 1-41                                               [1, 512, 48, 18]          2,359,808\n",
       "├─BatchNorm2d: 1-42                                          [1, 512, 48, 18]          1,024\n",
       "├─Conv2d: 1-43                                               [1, 64, 96, 36]           1,088\n",
       "├─Conv2d: 1-44                                               [1, 64, 96, 36]           4,160\n",
       "├─BatchNorm2d: 1-45                                          [1, 64, 96, 36]           128\n",
       "├─Conv2d: 1-46                                               [1, 128, 96, 36]          4,224\n",
       "├─Conv2d: 1-47                                               [1, 128, 96, 36]          147,584\n",
       "├─BatchNorm2d: 1-48                                          [1, 128, 96, 36]          256\n",
       "├─Conv2d: 1-49                                               [1, 256, 48, 18]          16,640\n",
       "├─Conv2d: 1-50                                               [1, 256, 48, 18]          65,792\n",
       "├─BatchNorm2d: 1-51                                          [1, 256, 48, 18]          512\n",
       "├─Conv2d: 1-52                                               [1, 512, 48, 18]          66,048\n",
       "├─Conv2d: 1-53                                               [1, 512, 48, 18]          2,359,808\n",
       "├─BatchNorm2d: 1-54                                          [1, 512, 48, 18]          1,024\n",
       "├─Conv2d: 1-55                                               [1, 512, 48, 18]          2,359,808\n",
       "├─BatchNorm2d: 1-56                                          [1, 512, 48, 18]          1,024\n",
       "├─Conv2d: 1-57                                               [1, 128, 96, 36]          8,320\n",
       "├─Conv2d: 1-58                                               [1, 128, 96, 36]          16,512\n",
       "├─BatchNorm2d: 1-59                                          [1, 128, 96, 36]          256\n",
       "├─Conv2d: 1-60                                               [1, 256, 48, 18]          33,024\n",
       "├─Conv2d: 1-61                                               [1, 256, 48, 18]          65,792\n",
       "├─BatchNorm2d: 1-62                                          [1, 256, 48, 18]          512\n",
       "├─Conv2d: 1-63                                               [1, 512, 48, 18]          131,584\n",
       "├─Conv2d: 1-64                                               [1, 512, 48, 18]          262,656\n",
       "├─BatchNorm2d: 1-65                                          [1, 512, 48, 18]          1,024\n",
       "├─Conv2d: 1-66                                               [1, 512, 48, 18]          262,656\n",
       "├─BatchNorm2d: 1-67                                          [1, 512, 48, 18]          1,024\n",
       "├─Sequential: 1-68                                           [1, 2]                    --\n",
       "│    └─AdaptiveAvgPool2d: 2-75                               [1, 512, 1, 1]            --\n",
       "│    └─Flatten: 2-76                                         [1, 512]                  --\n",
       "│    └─Dropout: 2-77                                         [1, 512]                  --\n",
       "│    └─Linear: 2-78                                          [1, 2]                    1,026\n",
       "==============================================================================================================\n",
       "Total params: 12,063,654\n",
       "Trainable params: 12,063,654\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (G): 9.18\n",
       "==============================================================================================================\n",
       "Input size (MB): 0.01\n",
       "Forward/backward pass size (MB): 175.43\n",
       "Params size (MB): 48.09\n",
       "Estimated Total Size (MB): 223.53\n",
       "=============================================================================================================="
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 7
  },
  {
   "cell_type": "code",
   "id": "9e035836b1e3d972",
   "metadata": {
    "collapsed": false,
    "tags": [],
    "ExecuteTime": {
     "end_time": "2025-04-09T13:21:03.599624Z",
     "start_time": "2025-04-09T13:21:02.888371Z"
    }
   },
   "source": [
    "model = ZHJNet().to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "left cuda:0 cuda:0\n",
      "right cuda:0 cuda:0\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "cell_type": "code",
   "id": "3a16d584516315d9",
   "metadata": {
    "collapsed": false,
    "tags": [],
    "is_executing": true,
    "ExecuteTime": {
     "end_time": "2024-09-02T13:06:50.685248Z",
     "start_time": "2024-09-02T13:06:47.359370Z"
    }
   },
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "num_epochs = 200\n",
    "start_epoch = 0\n",
    "Min_Loss = 1000000\n",
    "MAX_UAR = 0\n",
    "logs = []\n",
    "total_train = len(train_dataset)\n",
    "\n",
    "for epoch in range(0, num_epochs):\n",
    "    model.train()\n",
    "    train_loss = 0.0\n",
    "    for inputs, labels in tqdm(train_loader):\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item() * inputs.size(0)\n",
    "\n",
    "    model.eval()\n",
    "    correct_train = 0\n",
    "    correct_test = 0\n",
    "    total_test = 0\n",
    "\n",
    "    TP = 0\n",
    "    FN = 0\n",
    "    TN = 0\n",
    "    FP = 0\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in val_loader:\n",
    "            outputs = model(inputs)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            _, labels_max = torch.max(labels, 1)\n",
    "            total_test += labels.size(0)\n",
    "            correct_test += (predicted == labels_max).sum().item()\n",
    "\n",
    "            TN += ((predicted == 1) & (labels_max == 1)).sum().item()\n",
    "            FN += ((predicted == 1) & (labels_max == 0)).sum().item()\n",
    "            TP += ((predicted == 0) & (labels_max == 0)).sum().item()\n",
    "            FP += ((predicted == 0) & (labels_max == 1)).sum().item()\n",
    "\n",
    "    Se = TP / (TP + FN) if (TP + FN) > 0 else 0\n",
    "    Sp = TN / (TN + FP) if (TN + FP) > 0 else 0\n",
    "    Pr = TP / (TP + FP) if (TP + FP) > 0 else 0\n",
    "    Acc = (TP + TN) / (TP + FP + TN + FN) if (TP + FP + TN + FN) > 0 else 0\n",
    "    UAR = (Se + Sp) / 2\n",
    "    F1 = (2 * Pr * Se) / (Pr + Se) if (Pr + Se) > 0 else 0\n",
    "    logs.append([epoch, train_loss / total_train, Se, Sp, Pr, F1, Acc, UAR])\n",
    "    print(f\"Epoch [{epoch + 1}/{num_epochs}], \"\n",
    "          f\"Train Loss: {(train_loss / total_train):.7f}, \"\n",
    "          f\"TRAIN-Acc: {(correct_train / total_train) * 100:.4f}% \"\n",
    "          f\"VAL--Acc: {(correct_test / total_test) * 100:.4f}% \"\n",
    "          f\"Se:{Se * 100:.4f} \"\n",
    "          f\"Sp:{Sp * 100:.4f} \"\n",
    "          f\"Pr:{Pr * 100:.4f} \"\n",
    "          f\"F1: {F1 * 100:.4f}% \"\n",
    "          f\"Acc: {Acc * 100:.4f}% \"\n",
    "          f\"UAR: {UAR * 100:.4f}% \")\n",
    "    torch.save({\n",
    "            'model_state_dict': model.state_dict(),\n",
    "        }, f'results/TwoMouses/model_checkpoint_TwoMouses_{epoch}.pth')\n",
    "\n",
    "print('Training Finished')\n",
    "\n",
    "import csv\n",
    "\n",
    "# 打开文件并将数组写入CSV文件\n",
    "with open('results/TwoMouses/model_TwoMouses.csv', mode='w',\n",
    "          newline='') as file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerows(logs)"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/1098 [00:03<55:02,  3.01s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[11], line 17\u001B[0m\n\u001B[0;32m     15\u001B[0m outputs \u001B[38;5;241m=\u001B[39m model(inputs)\n\u001B[0;32m     16\u001B[0m loss \u001B[38;5;241m=\u001B[39m criterion(outputs, labels)\n\u001B[1;32m---> 17\u001B[0m \u001B[43mloss\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbackward\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     18\u001B[0m optimizer\u001B[38;5;241m.\u001B[39mstep()\n\u001B[0;32m     19\u001B[0m train_loss \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m loss\u001B[38;5;241m.\u001B[39mitem() \u001B[38;5;241m*\u001B[39m inputs\u001B[38;5;241m.\u001B[39msize(\u001B[38;5;241m0\u001B[39m)\n",
      "File \u001B[1;32mC:\\ProgramData\\Anaconda3\\envs\\spikingjelly\\lib\\site-packages\\torch\\_tensor.py:522\u001B[0m, in \u001B[0;36mTensor.backward\u001B[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001B[0m\n\u001B[0;32m    512\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m has_torch_function_unary(\u001B[38;5;28mself\u001B[39m):\n\u001B[0;32m    513\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m handle_torch_function(\n\u001B[0;32m    514\u001B[0m         Tensor\u001B[38;5;241m.\u001B[39mbackward,\n\u001B[0;32m    515\u001B[0m         (\u001B[38;5;28mself\u001B[39m,),\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    520\u001B[0m         inputs\u001B[38;5;241m=\u001B[39minputs,\n\u001B[0;32m    521\u001B[0m     )\n\u001B[1;32m--> 522\u001B[0m \u001B[43mtorch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mautograd\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbackward\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    523\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mgradient\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mretain_graph\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcreate_graph\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43minputs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43minputs\u001B[49m\n\u001B[0;32m    524\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32mC:\\ProgramData\\Anaconda3\\envs\\spikingjelly\\lib\\site-packages\\torch\\autograd\\__init__.py:266\u001B[0m, in \u001B[0;36mbackward\u001B[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001B[0m\n\u001B[0;32m    261\u001B[0m     retain_graph \u001B[38;5;241m=\u001B[39m create_graph\n\u001B[0;32m    263\u001B[0m \u001B[38;5;66;03m# The reason we repeat the same comment below is that\u001B[39;00m\n\u001B[0;32m    264\u001B[0m \u001B[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001B[39;00m\n\u001B[0;32m    265\u001B[0m \u001B[38;5;66;03m# calls in the traceback and some print out the last line\u001B[39;00m\n\u001B[1;32m--> 266\u001B[0m \u001B[43mVariable\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_execution_engine\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrun_backward\u001B[49m\u001B[43m(\u001B[49m\u001B[43m  \u001B[49m\u001B[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001B[39;49;00m\n\u001B[0;32m    267\u001B[0m \u001B[43m    \u001B[49m\u001B[43mtensors\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    268\u001B[0m \u001B[43m    \u001B[49m\u001B[43mgrad_tensors_\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    269\u001B[0m \u001B[43m    \u001B[49m\u001B[43mretain_graph\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    270\u001B[0m \u001B[43m    \u001B[49m\u001B[43mcreate_graph\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    271\u001B[0m \u001B[43m    \u001B[49m\u001B[43minputs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    272\u001B[0m \u001B[43m    \u001B[49m\u001B[43mallow_unreachable\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[0;32m    273\u001B[0m \u001B[43m    \u001B[49m\u001B[43maccumulate_grad\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[0;32m    274\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-11T07:09:44.803444Z",
     "start_time": "2025-04-11T07:09:17.010952Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import librosa\n",
    "model = ZHJNet().cuda()\n",
    "checkpoint = torch.load(\n",
    "    'model_checkpoint_TwoMouses_141.pth')\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "model.eval()\n",
    "\n",
    "correct_test = 0\n",
    "total_test = 0\n",
    "TP = 0\n",
    "FN = 0\n",
    "TN = 0\n",
    "FP = 0\n",
    "ori_labels = []\n",
    "pred_labels = []\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in test_loader:\n",
    "        outputs = model(inputs)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        _, labels_max = torch.max(labels, 1)\n",
    "        pred_labels.append(predicted)\n",
    "        ori_labels.append(labels_max)\n",
    "        total_test += labels.size(0)\n",
    "        correct_test += (predicted == labels_max).sum().item()\n",
    "\n",
    "        TN += ((predicted == 1) & (labels_max == 1)).sum().item()\n",
    "        FN += ((predicted == 1) & (labels_max == 0)).sum().item()\n",
    "        TP += ((predicted == 0) & (labels_max == 0)).sum().item()\n",
    "        FP += ((predicted == 0) & (labels_max == 1)).sum().item()\n",
    "\n",
    "Se = TP / (TP + FN) if (TP + FN) > 0 else 0\n",
    "Sp = TN / (TN + FP) if (TN + FP) > 0 else 0\n",
    "Pr = TP / (TP + FP) if (TP + FP) > 0 else 0\n",
    "Acc = (TP + TN) / (TP + FP + TN + FN) if (TP + FP + TN + FN) > 0 else 0\n",
    "UAR = (Se + Sp) / 2\n",
    "F1 = (2 * Pr * Se) / (Pr + Se) if (Pr + Se) > 0 else 0\n",
    "\n",
    "print(f\"TEST-Acc: {(correct_test / total_test) * 100:.4f}% \"\n",
    "      f\"Se:{Se * 100:.4f} \"\n",
    "      f\"Sp:{Sp * 100:.4f} \"\n",
    "      f\"Pr:{Pr * 100:.4f} \"\n",
    "      f\"F1: {F1 * 100:.4f}% \"\n",
    "      f\"Acc: {Acc * 100:.4f}% \"\n",
    "      f\"UAR: {UAR * 100:.4f}% \")"
   ],
   "id": "7adf9542ecf289e8",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "left cuda:0 cuda:0\n",
      "right cuda:0 cuda:0\n",
      "TEST-Acc: 96.2187% Se:92.7072 Sp:97.1923 Pr:90.1531 F1: 91.4123% Acc: 96.2187% UAR: 94.9498% \n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "c8a0e9a0ae937efd"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
